{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy\n",
    "from tempfile import NamedTemporaryFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explored  scc  starting time\n",
      "0         0    0              0\n",
      "1         1    1              1\n",
      "2         2    2              2\n",
      "3         3    3              3\n",
      "4         4    4              4\n",
      "5         5    5              5\n",
      "6         6    6              6\n",
      "7         7    7              7\n",
      "8         8    8              8\n",
      "9         9    9              9\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('nodes.csv'):\n",
    "    os.remove('nodes.csv')\n",
    "with open('nodes.csv', 'a') as nodes_file: \n",
    "    d2 = {'explored': [0,1,2,3,4,5,6,7,8,9], 'scc': [0,1,2,3,4,5,6,7,8,9], 'starting time': [0,1,2,3,4,5,6,7,8,9]}\n",
    "    df2 = pd.DataFrame(data=d2)\n",
    "    df2.to_csv(nodes_file, header=True, index=False)\n",
    "graph_stored = pd.read_csv(\"nodes.csv\")\n",
    "print(graph_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "rev_all = []\n",
    "\n",
    "for chunk in pd.read_csv(\"nodes.csv\", chunksize=5):\n",
    "    list_chunk = chunk[\"explored\"].values.tolist()\n",
    "    list_chunk_deep = copy.deepcopy(list_chunk)\n",
    "    #print(list_chunk)\n",
    "    list_chunk_deep.reverse()\n",
    "    #print(list_chunk)\n",
    "    rev_all = list_chunk_deep + rev_all\n",
    "    i = i+5\n",
    "print(rev_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo:  Update cell of csv file using scalar (Not Working)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas loc vs. iloc vs. ix vs. at vs. iat?\n",
    "\n",
    "**loc:** only work on index <br>\n",
    "**iloc:** work on position <br>\n",
    "**ix:** You can get data from dataframe without it being in the index <br>\n",
    "**at:** get scalar values. It's a very fast loc <br>\n",
    "**iat:** Get scalar values. It's a very fast iloc <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explored  scc  starting time\n",
      "7       999    7              7\n",
      "Empty DataFrame\n",
      "Columns: [7, 999, 7.1, 7.2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for chunk in pd.read_csv(\"nodes.csv\", chunksize=5):\n",
    "    #chunk_deep = copy.deepcopy(chunk)\n",
    "    #chunk_deep.loc[chunk_deep['starting time'] == 7]\n",
    "    if not chunk.loc[chunk['starting time'] == 7].empty:\n",
    "        #with open('nodes.csv', 'w') as nodes_file: \n",
    "        index_loc = chunk.loc[chunk['starting time'] == 7].index\n",
    "        chunk.loc[index_loc , \"explored\"] = 999\n",
    "        print(chunk.loc[index_loc])\n",
    "        chunk.loc[index_loc].to_csv(\"nodes.csv\", index_label=index_loc, header=False)\n",
    "        \n",
    "\n",
    "graph_stored = pd.read_csv(\"nodes.csv\")\n",
    "print(graph_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-600f046b4541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m#reader = csv.DictReader(nodes_file, fieldnames=fields)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'starting time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'explored'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m999\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aishwaya/anaconda2/lib/python2.7/csv.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# Used only for its side effect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "fields = ['explored', 'scc', 'starting time']\n",
    "\n",
    "\n",
    "for chunk in pd.read_csv(\"nodes.csv\", chunksize=5):\n",
    "    #chunk_deep = copy.deepcopy(chunk)\n",
    "    #chunk_deep.loc[chunk_deep['starting time'] == 7]\n",
    "    if not chunk.loc[chunk['starting time'] == 7].empty:\n",
    "        #with open('nodes.csv', 'w') as nodes_file: \n",
    "        index_loc = chunk.loc[chunk['starting time'] == 7].index\n",
    "        #chunk.loc[index_loc , \"explored\"] = 999\n",
    "        with open('nodes.csv', 'a') as nodes_file: \n",
    "            #reader = csv.DictReader(nodes_file, fieldnames=fields)\n",
    "            writer = csv.DictWriter(nodes_file, fieldnames=fields)\n",
    "            for row in reader:\n",
    "                print(row)\n",
    "                row['starting time'], row['explored']= 999, 999\n",
    "                row = {'explored': row['explored'], 'scc': row['scc'], 'starting time': row['starting time']}\n",
    "                writer.writerow(row)\n",
    "\n",
    "graph_stored = pd.read_csv(\"nodes.csv\")\n",
    "print(graph_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explored  scc  starting time\n",
      "0         0    0              0\n",
      "1         1    1              1\n",
      "2         2    2              2\n",
      "3         3    3              3\n",
      "4         4    4              4\n",
      "5         5    5              5\n",
      "6         6    6              6\n",
      "7         7    7              7\n",
      "8         8    8              8\n",
      "9         9    9              9\n"
     ]
    }
   ],
   "source": [
    "fields = ['explored', 'scc', 'starting time']\n",
    "\n",
    "tempfile = NamedTemporaryFile(mode='a', delete=False)\n",
    "\n",
    "with open('nodes.csv', 'r') as nodes_file: \n",
    "    reader = csv.DictReader(nodes_file, fieldnames=fields)\n",
    "    writer = csv.DictWriter(tempfile, fieldnames=fields)\n",
    "    for row in reader:\n",
    "        if row['starting time'] < 5:\n",
    "            row['starting time'], row['explored']= 0, 1\n",
    "        row = {'explored': row['explored'], 'scc': row['scc'], 'starting time': row['starting time']}\n",
    "        writer.writerow(row)\n",
    "        \n",
    "graph_stored = pd.read_csv(\"nodes.csv\")\n",
    "print(graph_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open file 'nodes.csv', mode 'a' at 0x10b6f2150>\n"
     ]
    }
   ],
   "source": [
    "with open('nodes.csv', 'a') as nodes_file: \n",
    "    print(nodes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
